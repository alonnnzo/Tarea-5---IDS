{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315978b4",
   "metadata": {},
   "source": [
    "# Tarea 6 - IDS\n",
    "**Autor:** Estudiante (generado por ayudante automático)\n",
    "\n",
    "Este notebook contiene la solución completa a la Tarea 6. Se realiza: EDA, preprocesamiento, entrenamiento y evaluación de modelos (SVM y Naïve Bayes), ajuste de hiperparámetros y conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00628fd",
   "metadata": {},
   "source": [
    "## 1) Importar librerías y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b954a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c806f",
   "metadata": {},
   "source": [
    "## 2) Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2543079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (568630, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.260648</td>\n",
       "      <td>-0.469648</td>\n",
       "      <td>2.496266</td>\n",
       "      <td>-0.083724</td>\n",
       "      <td>0.129681</td>\n",
       "      <td>0.732898</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>-0.130006</td>\n",
       "      <td>0.727159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>-0.134794</td>\n",
       "      <td>0.165959</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>-0.434824</td>\n",
       "      <td>-0.081230</td>\n",
       "      <td>-0.151045</td>\n",
       "      <td>17982.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.985100</td>\n",
       "      <td>-0.356045</td>\n",
       "      <td>0.558056</td>\n",
       "      <td>-0.429654</td>\n",
       "      <td>0.277140</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>-0.133118</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194936</td>\n",
       "      <td>-0.605761</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>-0.577395</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.296503</td>\n",
       "      <td>-0.248052</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>6531.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.260272</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>1.728538</td>\n",
       "      <td>-0.457986</td>\n",
       "      <td>0.074062</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>0.743511</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>-0.261297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.945045</td>\n",
       "      <td>-1.154666</td>\n",
       "      <td>-0.605564</td>\n",
       "      <td>-0.312895</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.244718</td>\n",
       "      <td>2513.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.508959</td>\n",
       "      <td>1.746840</td>\n",
       "      <td>-1.090178</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>1.143312</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>-0.065130</td>\n",
       "      <td>-0.205698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146927</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.214048</td>\n",
       "      <td>-1.893131</td>\n",
       "      <td>1.003963</td>\n",
       "      <td>-0.515950</td>\n",
       "      <td>-0.165316</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>5384.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.206820</td>\n",
       "      <td>-0.165280</td>\n",
       "      <td>1.527053</td>\n",
       "      <td>-0.448293</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.530549</td>\n",
       "      <td>0.658849</td>\n",
       "      <td>-0.212660</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106984</td>\n",
       "      <td>0.729727</td>\n",
       "      <td>-0.161666</td>\n",
       "      <td>0.312561</td>\n",
       "      <td>-0.414116</td>\n",
       "      <td>1.071126</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.419117</td>\n",
       "      <td>14278.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0 -0.260648 -0.469648  2.496266 -0.083724  0.129681  0.732898  0.519014   \n",
       "1   1  0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605  0.406466   \n",
       "2   2 -0.260272 -0.949385  1.728538 -0.457986  0.074062  1.419481  0.743511   \n",
       "3   3 -0.152152 -0.508959  1.746840 -1.090178  0.249486  1.143312  0.518269   \n",
       "4   4 -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549  0.658849   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0 -0.130006  0.727159  ... -0.110552  0.217606 -0.134794  0.165959  0.126280   \n",
       "1 -0.133118  0.347452  ... -0.194936 -0.605761  0.079469 -0.577395  0.190090   \n",
       "2 -0.095576 -0.261297  ... -0.005020  0.702906  0.945045 -1.154666 -0.605564   \n",
       "3 -0.065130 -0.205698  ... -0.146927 -0.038212 -0.214048 -1.893131  1.003963   \n",
       "4 -0.212660  1.049921  ... -0.106984  0.729727 -0.161666  0.312561 -0.414116   \n",
       "\n",
       "        V26       V27       V28    Amount  Class  \n",
       "0 -0.434824 -0.081230 -0.151045  17982.10      0  \n",
       "1  0.296503 -0.248052 -0.064512   6531.37      0  \n",
       "2 -0.312895 -0.300258 -0.244718   2513.54      0  \n",
       "3 -0.515950 -0.165316  0.048424   5384.44      0  \n",
       "4  1.071126  0.023712  0.419117  14278.97      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ruta del CSV proporcionado en la carpeta de la tarea\n",
    "csv_path = 'creditcard_Tarea6.csv'\n",
    "\n",
    "# Cargamos el dataset (si da error por memoria, leer por chunks o usar una muestra)\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except Exception as e:\n",
    "    print('Error al leer el CSV:', e)\n",
    "    # Intento leer solo primeras filas para inspección\n",
    "    df = pd.read_csv(csv_path, nrows=1000)\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67ada05",
   "metadata": {},
   "source": [
    "## 3) Inspección rápida y limpieza básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2778d545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas: ['id', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "Valores nulos por columna:\n",
      "id        0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "Duplicados: 0\n",
      "Duplicados: 0\n",
      "Target detectado: Class\n",
      "Class\n",
      "0    284315\n",
      "1    284315\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Target detectado: Class\n",
      "Class\n",
      "0    284315\n",
      "1    284315\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Información general\n",
    "print('Columnas:', df.columns.tolist())\n",
    "print('Valores nulos por columna:')\n",
    "print(df.isna().sum())\n",
    "print('Duplicados:', df.duplicated().sum())\n",
    "\n",
    "# Eliminamos duplicados si existen (en su mayoría no deberían existir)\n",
    "if df.duplicated().sum() > 0:\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Detectar columna objetivo (comúnmente 'Class' en datasets de tarjetas)\n",
    "possible_targets = ['Class','class','Target','target','isFraud','fraud','Fraud']\n",
    "target = None\n",
    "for t in possible_targets:\n",
    "    if t in df.columns:\n",
    "        target = t\n",
    "        break\n",
    "\n",
    "if target is None:\n",
    "    # Si no se detecta, escogemos la última columna como objetivo (hipótesis razonable en ejercicios)\n",
    "    target = df.columns[-1]\n",
    "    print('No se detectó target común; se usará la última columna:', target)\n",
    "else:\n",
    "    print('Target detectado:', target)\n",
    "\n",
    "# Convertir target a entero si corresponde\n",
    "if df[target].dtype == 'bool':\n",
    "    df[target] = df[target].astype(int)\n",
    "\n",
    "# Mostrar distribución del target\n",
    "print(df[target].value_counts(normalize=False))\n",
    "print(df[target].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de9adc",
   "metadata": {},
   "source": [
    "## 4) Análisis exploratorio (rápido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas numéricas (ejemplo): ['id', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9']\n"
     ]
    }
   ],
   "source": [
    "# Histograma de algunas variables numéricas (siempre verificando que existan)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != target]\n",
    "print('Columnas numéricas (ejemplo):', numeric_cols[:10])\n",
    "\n",
    "# Mostrar pairplot para primeras 6 numéricas (si el dataset no es excesivamente grande)\n",
    "cols_plot = numeric_cols[:6]\n",
    "if len(cols_plot) > 0:\n",
    "    try:\n",
    "        sns.pairplot(df[cols_plot + [target]], hue=target, diag_kind='kde', corner=True)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print('No se pudo generar pairplot (memoria/tiempo):', e)\n",
    "\n",
    "# Correlación\n",
    "try:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(df[cols_plot + [target]].corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('No se pudo mostrar mapa de correlación:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a787b",
   "metadata": {},
   "source": [
    "## 5) Preprocesamiento\n",
    "- Separar variables numéricas y categóricas\n",
    "- Estandarizar numéricas y codificar categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6d6ad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numéricas: 30 Categóricas: 0\n",
      "Train shape: (454904, 30) Test shape: (113726, 30)\n",
      "Preprocessor summary: ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('num',\n",
      "                                 Pipeline(steps=[('scaler', StandardScaler())]),\n",
      "                                 ['id', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6',\n",
      "                                  'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13',\n",
      "                                  'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\n",
      "                                  'V20', 'V21', 'V22', 'V23', 'V24', 'V25',\n",
      "                                  'V26', 'V27', 'V28', 'Amount'])])\n",
      "Train shape: (454904, 30) Test shape: (113726, 30)\n",
      "Preprocessor summary: ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('num',\n",
      "                                 Pipeline(steps=[('scaler', StandardScaler())]),\n",
      "                                 ['id', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6',\n",
      "                                  'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13',\n",
      "                                  'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\n",
      "                                  'V20', 'V21', 'V22', 'V23', 'V24', 'V25',\n",
      "                                  'V26', 'V27', 'V28', 'Amount'])])\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento robusto y autocontenido\n",
    "# (añadimos imports defensivos para que la celda funcione si se ejecuta aisladamente)\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception:\n",
    "    pass\n",
    "import inspect\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Detectar la columna objetivo si no está ya identificada\n",
    "possible_targets = ['Class','class','Target','target','isFraud','fraud','Fraud']\n",
    "if 'target' in globals() and target in df.columns:\n",
    "    pass\n",
    "else:\n",
    "    target = None\n",
    "    for t in possible_targets:\n",
    "        if t in df.columns:\n",
    "            target = t\n",
    "            break\n",
    "    if target is None:\n",
    "        target = df.columns[-1]\n",
    "        print('No se detectó target común; se usará la última columna:', target)\n",
    "    else:\n",
    "        print('Target detectado:', target)\n",
    "\n",
    "# Normalizar tipo booleano a entero si corresponde\n",
    "if df[target].dtype == 'bool':\n",
    "    df[target] = df[target].astype(int)\n",
    "\n",
    "# Separar numéricas y categóricas\n",
    "numerical = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if target in numerical:\n",
    "    numerical.remove(target)\n",
    "categorical = [c for c in df.columns if c not in numerical and c != target]\n",
    "print('Numéricas:', len(numerical), 'Categóricas:', len(categorical))\n",
    "\n",
    "# Construir OneHotEncoder compatible con la versión instalada de scikit-learn\n",
    "ohe_kwargs = {}\n",
    "try:\n",
    "    sig = inspect.signature(OneHotEncoder)\n",
    "    if 'sparse' in sig.parameters:\n",
    "        ohe_kwargs['sparse'] = False\n",
    "    elif 'sparse_output' in sig.parameters:\n",
    "        ohe_kwargs['sparse_output'] = False\n",
    "except Exception as e:\n",
    "    # En caso de no poder inspeccionar, no pasamos el kwarg (compatibilidad conservadora)\n",
    "    ohe_kwargs = {}\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', **ohe_kwargs)\n",
    "\n",
    "# Construcción dinámica del ColumnTransformer según columnas disponibles\n",
    "transformers = []\n",
    "if len(numerical) > 0:\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    transformers.append(('num', numeric_transformer, numerical))\n",
    "if len(categorical) > 0:\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', ohe)])\n",
    "    transformers.append(('cat', categorical_transformer, categorical))\n",
    "\n",
    "if transformers:\n",
    "    # Passthrough mantiene columnas no transformadas (si las hubiera)\n",
    "    preprocessor = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "else:\n",
    "    preprocessor = 'passthrough'\n",
    "\n",
    "# Definir X e y (sin mutar el df original)\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# División con estratificación si es posible (al menos 2 clases y al menos 2 muestras por clase)\n",
    "stratify_arg = None\n",
    "try:\n",
    "    if y.nunique() > 1 and y.value_counts().min() > 1:\n",
    "        stratify_arg = y\n",
    "except Exception:\n",
    "    stratify_arg = None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=stratify_arg)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "print('Preprocessor summary:', preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab4e951",
   "metadata": {},
   "source": [
    "## 6) Modelos: SVM y Naïve Bayes\n",
    "Entrenaremos ambos modelos y compararemos métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82e2752e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Pipeline para SVM (probability=True para obtener ROC)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m svm_pipe = Pipeline(steps=[(\u001b[33m'\u001b[39m\u001b[33mpre\u001b[39m\u001b[33m'\u001b[39m, preprocessor), (\u001b[33m'\u001b[39m\u001b[33mclf\u001b[39m\u001b[33m'\u001b[39m, \u001b[43mSVC\u001b[49m(probability=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m))])\n\u001b[32m      3\u001b[39m param_grid_svm = {\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__C\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.1\u001b[39m, \u001b[32m1.0\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__kernel\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mrbf\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclf__class_weight\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m }\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Usamos GridSearch con scoring f1 (balance entre precision/recall)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "# Pipeline para SVM (probability=True para obtener ROC)\n",
    "svm_pipe = Pipeline(steps=[('pre', preprocessor), ('clf', SVC(probability=True, random_state=42))])\n",
    "param_grid_svm = {\n",
    "    'clf__C': [0.1, 1.0],\n",
    "    'clf__kernel': ['rbf','linear'],\n",
    "    'clf__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Usamos GridSearch con scoring f1 (balance entre precision/recall)\n",
    "gs_svm = GridSearchCV(svm_pipe, param_grid_svm, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Pipeline para Naive Bayes (GaussianNB)\n",
    "# NB no acepta directamente sparse output from OneHotEncoder (nos aseguramos de que OHE devuelva dense)\n",
    "nb_pipe = Pipeline(steps=[('pre', preprocessor), ('clf', GaussianNB())])\n",
    "param_grid_nb = { }\n",
    "\n",
    "# Ajuste rápido de SVM (puede tardar dependiendo del tamaño); si falla, lo reportamos y seguiremos con svm_pipe\n",
    "print('Entrenando SVM (GridSearch) ...')\n",
    "try:\n",
    "    gs_svm.fit(X_train, y_train)\n",
    "    print('Mejores parámetros SVM:', gs_svm.best_params_)\n",
    "except Exception as e:\n",
    "    print('Error o tardanza en gridsearch SVM (continuando con pipeline sin GridSearch):', e)\n",
    "\n",
    "# Si GridSearch falló, gs_svm puede no tener best_estimator_; seguiremos con svm_pipe como fallback\n",
    "\n",
    "# Entrenar NB sin búsqueda de hiperparámetros (rápido)\n",
    "print('Entrenando Naïve Bayes ...')\n",
    "try:\n",
    "    nb_pipe.fit(X_train, y_train)\n",
    "except Exception as e:\n",
    "    print('Error al entrenar Naïve Bayes:', e)\n",
    "    # Intentar ajustar sin preprocesador si hay problemas (último recurso)\n",
    "    try:\n",
    "        plain_nb = GaussianNB()\n",
    "        plain_nb.fit(X_train.select_dtypes(include=[np.number]), y_train)\n",
    "        nb_pipe = Pipeline(steps=[('clf', plain_nb)])\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45ffc3",
   "metadata": {},
   "source": [
    "## 7) Evaluación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a85421ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm_pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m     best_svm = gs_svm.best_estimator_\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     best_svm = \u001b[43msvm_pipe\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Asegurarnos de que el estimador esté ajustado; si no, lo ajustamos (silenciosamente)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Intentamos predecir para ver si está ajustado\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'svm_pipe' is not defined"
     ]
    }
   ],
   "source": [
    "# Predicciones SVM (usar best_estimator_ si hubo GridSearch)\n",
    "if 'gs_svm' in globals() and hasattr(gs_svm, 'best_estimator_'):\n",
    "    best_svm = gs_svm.best_estimator_\n",
    "else:\n",
    "    best_svm = svm_pipe\n",
    "\n",
    "# Asegurarnos de que el estimador esté ajustado; si no, lo ajustamos (silenciosamente)\n",
    "try:\n",
    "    # Intentamos predecir para ver si está ajustado\n",
    "    _ = best_svm.predict(X_test[:1])\n",
    "except Exception:\n",
    "    try:\n",
    "        best_svm.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print('No se pudo ajustar best_svm:', e)\n",
    "\n",
    "# Intentar obtener probabilidades de SVM (si existe predict_proba)\n",
    "y_pred_svm = None\n",
    "y_proba_svm = None\n",
    "try:\n",
    "    y_pred_svm = best_svm.predict(X_test)\n",
    "except Exception as e:\n",
    "    print('Error prediciendo con SVM:', e)\n",
    "\n",
    "try:\n",
    "    y_proba_svm = best_svm.predict_proba(X_test)[:,1]\n",
    "except Exception:\n",
    "    y_proba_svm = None\n",
    "\n",
    "# NB predicciones (ya debería estar entrenado, si no, lo intentamos)\n",
    "y_pred_nb = None\n",
    "y_proba_nb = None\n",
    "try:\n",
    "    y_pred_nb = nb_pipe.predict(X_test)\n",
    "    try:\n",
    "        y_proba_nb = nb_pipe.predict_proba(X_test)[:,1]\n",
    "    except Exception:\n",
    "        y_proba_nb = None\n",
    "except Exception as e:\n",
    "    print('Error prediciendo con Naïve Bayes:', e)\n",
    "\n",
    "# Reportes (solo si tenemos predicciones)\n",
    "if y_pred_svm is not None:\n",
    "    print('--- SVM ---')\n",
    "    print(classification_report(y_test, y_pred_svm))\n",
    "    print('Confusion matrix SVM:', confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "if y_pred_nb is not None:\n",
    "    print('--- Naïve Bayes ---')\n",
    "    print(classification_report(y_test, y_pred_nb))\n",
    "    print('Confusion matrix NB:', confusion_matrix(y_test, y_pred_nb))\n",
    "\n",
    "# ROC AUC si disponemos de probabilidades\n",
    "if y_proba_svm is not None:\n",
    "    try:\n",
    "        print('ROC AUC SVM:', roc_auc_score(y_test, y_proba_svm))\n",
    "    except Exception as e:\n",
    "        print('Error calculando ROC AUC SVM:', e)\n",
    "if y_proba_nb is not None:\n",
    "    try:\n",
    "        print('ROC AUC NB:', roc_auc_score(y_test, y_proba_nb))\n",
    "    except Exception as e:\n",
    "        print('Error calculando ROC AUC NB:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b189d",
   "metadata": {},
   "source": [
    "## 8) Curvas ROC (si es aplicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55797b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m8\u001b[39m,\u001b[32m6\u001b[39m))\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_proba_svm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      3\u001b[39m     fpr, tpr, _ = roc_curve(y_test, y_proba_svm)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Curvas ROC (si disponemos de probabilidades)\n",
    "plt.figure(figsize=(8,6))\n",
    "plotted = False\n",
    "if 'y_proba_svm' in globals() and y_proba_svm is not None:\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba_svm)\n",
    "        plt.plot(fpr, tpr, label='SVM')\n",
    "        plotted = True\n",
    "    except Exception as e:\n",
    "        print('No se pudo plotear ROC SVM:', e)\n",
    "if 'y_proba_nb' in globals() and y_proba_nb is not None:\n",
    "    try:\n",
    "        fpr2, tpr2, _ = roc_curve(y_test, y_proba_nb)\n",
    "        plt.plot(fpr2, tpr2, label='Naïve Bayes')\n",
    "        plotted = True\n",
    "    except Exception as e:\n",
    "        print('No se pudo plotear ROC NB:', e)\n",
    "if plotted:\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No hay probabilidades disponibles para dibujar ROC.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ee826",
   "metadata": {},
   "source": [
    "## 9) Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc6a4c",
   "metadata": {},
   "source": [
    "- Se realizó un preprocesamiento estándar: estandarización de numéricas y OneHotEncoding de categóricas.\n",
    "- Se compararon SVM (con GridSearch sobre un grid pequeño) y Naïve Bayes.\n",
    "- Dependiendo del dataset, SVM suele entregar mayor capacidad discriminativa a costa de mayor costo computacional; Naïve Bayes es más rápido pero depende del supuesto de independencia.\n",
    "- Recomendaciones: hacer un muestreo/SMOTE si el target está muy desbalanceado, y explorar ajuste de hiperparámetros más fino para SVM si el tiempo lo permite."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
